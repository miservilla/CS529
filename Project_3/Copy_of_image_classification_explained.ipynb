{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee08280c85d44e6cadfaab34fd38e5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ca3581d5a6446b3aca7cbbe716a6572",
              "IPY_MODEL_6880ab4966b9481cb2f3845df5f74d21",
              "IPY_MODEL_e47ee1a0f5ec4becbfd4cfa6386b7790"
            ],
            "layout": "IPY_MODEL_91a29b728be64477a1a6f0a085579a6a"
          }
        },
        "5ca3581d5a6446b3aca7cbbe716a6572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef876a26d0a4a359012bb1647e091a5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_67b1740da5d0499e9b68a5c8b09d8b43",
            "value": "Resolving data files: 100%"
          }
        },
        "6880ab4966b9481cb2f3845df5f74d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_330e399ff78048e58bc5a69ef82806f0",
            "max": 4750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b01c2719e45448c8a407bec54ddf2d69",
            "value": 4750
          }
        },
        "e47ee1a0f5ec4becbfd4cfa6386b7790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860770b6e34e402b83ddde00891ac855",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_042af7b1b40c4519ab07980cc6b9e6d6",
            "value": " 4750/4750 [00:01&lt;00:00, 2366.57it/s]"
          }
        },
        "91a29b728be64477a1a6f0a085579a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef876a26d0a4a359012bb1647e091a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b1740da5d0499e9b68a5c8b09d8b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "330e399ff78048e58bc5a69ef82806f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b01c2719e45448c8a407bec54ddf2d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "860770b6e34e402b83ddde00891ac855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "042af7b1b40c4519ab07980cc6b9e6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5315730f3eb349dbbd60b4642177e894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c3785c942a54eccbd92c84bf6d495e5",
              "IPY_MODEL_4e5107d30cd049f493e8156dc4c064de",
              "IPY_MODEL_53d562d874bf41d0be884ab502f01cab"
            ],
            "layout": "IPY_MODEL_61c7ae3bc56c4824bdd2bac18007134b"
          }
        },
        "5c3785c942a54eccbd92c84bf6d495e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685fa914b5674c8aae26a2c05572fcf3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4c16827c780e40179c5d5711bfbe5e48",
            "value": "Filter:   0%"
          }
        },
        "4e5107d30cd049f493e8156dc4c064de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c63e48f311f24c91ab3681e78ce599c0",
            "max": 3800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2048b10cfd6434e85cad094dbee06dc",
            "value": 0
          }
        },
        "53d562d874bf41d0be884ab502f01cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e7560d68b640db9b7849de00a48f19",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7c1e7f3bc5804a31a3567369b23a5f5d",
            "value": " 0/3800 [00:50&lt;?, ? examples/s]"
          }
        },
        "61c7ae3bc56c4824bdd2bac18007134b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "685fa914b5674c8aae26a2c05572fcf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c16827c780e40179c5d5711bfbe5e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c63e48f311f24c91ab3681e78ce599c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2048b10cfd6434e85cad094dbee06dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02e7560d68b640db9b7849de00a48f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c1e7f3bc5804a31a3567369b23a5f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwb1Sdi0QASD"
      },
      "source": [
        "# Fine-Tuning Vision Transformers for Image Classification\n",
        "\n",
        "Just as transformers-based models have revolutionized NLP, we're now seeing an explosion of papers applying them to all sorts of other domains. One of the most revolutionary of these was the Vision Transformer (ViT), which was introduced in [June 2021](https://arxiv.org/abs/2010.11929) by a team of researchers at Google Brain.\n",
        "\n",
        "This paper explored how you can tokenize images, just as you would tokenize sentences, so that they can be passed to transformer models for training. Its quite a simple concept, really...\n",
        "\n",
        "1. Split an image into a grid of sub-image patches\n",
        "1. Embed each patch with a linear projection\n",
        "1. Each embedded patch becomes a token, and the resulting sequence of embedded patches is the sequence you pass to the model.\n",
        "\n",
        "![vit_figure.png](https://raw.githubusercontent.com/google-research/vision_transformer/main/vit_figure.png)\n",
        "\n",
        "\n",
        "It turns out that once you've done the above, you can pre-train and finetune transformers just as you're used to with NLP tasks. Pretty sweet üòé.\n",
        "\n",
        "---\n",
        "\n",
        "In this notebook, we'll walk through how to leverage ü§ó `datasets` to download and process image classification datasets, and then use them to fine-tune a pre-trained ViT with ü§ó `transformers`. \n",
        "\n",
        "To get started, lets first install both those packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xKo7kiHvSNp"
      },
      "source": [
        "# blocks output in Colab üíÑ\n",
        "%%capture\n",
        "\n",
        "! pip install datasets transformers"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5X9j8AhPqzn"
      },
      "source": [
        "## Load a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svh5XNF3T1bQ"
      },
      "source": [
        "Let's start by loading a small image classification dataset and taking a look at its structure.\n",
        "\n",
        "We'll use the [`beans`](https://huggingface.co/datasets/beans) dataset, which is a collection of pictures of healthy and unhealthy bean leaves. üçÉ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elfg4GzYT2YY"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# ds = load_dataset('beans')\n",
        "# ds"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1p464qtjgck",
        "outputId": "6be57ed3-3e1d-4579-a295-4446994f53de"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"imagefolder\", data_dir=\"/content/drive/MyDrive/Colab Notebooks/CS529/train\", split='train').train_test_split(test_size=0.2)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "ee08280c85d44e6cadfaab34fd38e5ff",
            "5ca3581d5a6446b3aca7cbbe716a6572",
            "6880ab4966b9481cb2f3845df5f74d21",
            "e47ee1a0f5ec4becbfd4cfa6386b7790",
            "91a29b728be64477a1a6f0a085579a6a",
            "3ef876a26d0a4a359012bb1647e091a5",
            "67b1740da5d0499e9b68a5c8b09d8b43",
            "330e399ff78048e58bc5a69ef82806f0",
            "b01c2719e45448c8a407bec54ddf2d69",
            "860770b6e34e402b83ddde00891ac855",
            "042af7b1b40c4519ab07980cc6b9e6d6"
          ]
        },
        "id": "Wzbjl9ncjspe",
        "outputId": "0e7e0803-9838-4d86-bb4a-13c6d2844f56"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/4750 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee08280c85d44e6cadfaab34fd38e5ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imagefolder (/root/.cache/huggingface/datasets/imagefolder/default-a7188ad61d39f839/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 3800\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 950\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'] = dataset['train'].rename_column('label', 'labels')\n",
        "dataset['test'] = dataset['test'].rename_column('label', 'labels')"
      ],
      "metadata": {
        "id": "4fmUqAs37Zwm"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfMoMLjH9poo",
        "outputId": "8967f0e3-a37b-4e42-80ea-fe513d758ff6"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'labels'],\n",
              "    num_rows: 3800\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_valid = dataset['test'].train_test_split(test_size=0.5)\n",
        "dataset_test = dataset_valid['train']\n",
        "dataset_train = dataset['train']\n",
        "dataset_valid = dataset_valid['test']"
      ],
      "metadata": {
        "id": "s-qPT7bSrkkD"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n",
        "ds = DatasetDict({\n",
        "    'train': dataset_train,\n",
        "    'test': dataset_test,\n",
        "    'validation': dataset_valid}) "
      ],
      "metadata": {
        "id": "GLCjgW4lruda"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRMePpo7ikmD",
        "outputId": "aae472ce-e6d4-4ec5-c131-0be8b5cae861"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'labels'],\n",
              "        num_rows: 3800\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['image', 'labels'],\n",
              "        num_rows: 475\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['image', 'labels'],\n",
              "        num_rows: 475\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw0wLdPVVx-U"
      },
      "source": [
        "Let's take a look at the 400th example from the `'train'` split from the beans dataset. You'll notice each example from the dataset has 3 features:\n",
        "\n",
        "1. `image`: A PIL Image\n",
        "1. `image_file_path`: The `str` path to the image file that was loaded as `image`\n",
        "1. `labels`: A [`datasets.ClassLabel`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=classlabel#datasets.ClassLabel) feature, which we'll see as an integer representation of the label for a given example. (Later we'll see how to get the string class names, don't worry)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gxWwQAHWE-y",
        "outputId": "42333960-18f8-4466-e255-da1b76f3fc06"
      },
      "source": [
        "ex = ds['train'][400]\n",
        "ex"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F2F00175040>,\n",
              " 'labels': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the image üëÄ"
      ],
      "metadata": {
        "id": "W3T2xgo1ZpWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = ex['image']\n",
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "tWgpygDsYjNJ",
        "outputId": "e931a8d4-ba43-498e-da9c-90710c83671f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F2F00175040>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAH1ElEQVR4nDXVyZIkRxGAYd8iMjKzll6nR0jCMOMAB16C938EZGBIjDSj6anuqlxjcXcOGC/w23f78e9/+2t2VYS7+8fj6VBLsbw/fPcUgyzfXltrObfL22yIPddEnmL8+OOPX+d6nev9sethGvru4eXZW3GP6tDKslV4v7bmrFaFx462zRW222TV0ijdncSj5vXWaDdEiSFEmefdRLIQCnpgbbmWVgolVgeYvr1JZBJVAwQTdBZu6lqKOIAQA1jLq4YrDyp9edsWAGynQOVA++N4TtNtub7tfe89je/fbrVYiAhtBUbkSIGIDFqG2qrV4tEstLyXdRbPFdERkILE4xKHd45Iwg4WvHj8himH8HDomRHu7odOKG8LgwyBSCtQUnXV1vfMjtVbmZfPX97XzBTB3AQRHRGhaasUTAIDIwIjiUEGB8QND5/GH9K5fX8+PXUcwLy1hoJQFq+5rBMbhWMngm7WnNdczJuAuJHM+9729TiGMTEROQRFRwABAyQHAzLsWvqQMQvYCBgxChMxYc0rEEOr+6rrrSEBUAI5fv/nD6D29npZtio5l8BhGGMnuCuDKQMwugMgECISCmBwqC3d9vxP0r90eO9Qa22vXy59z10kBri8m3GPEkIauxjclMjRmnQpSuyKemsA0IGR22ZIgIbSERB4Q4iA4mwtTM4X185adgPuxmKtrjlyDH3XD0dJHQLXXLdtLblJjHI4DNW8AWoz2bnOKXQLABGaQXUIBIQAyB2bu1DxV25jWd2c7l4+NPftOpeyxRA4BEAy09vlbZ42o9h1QQIaWXUnJKgFpi+HU9rjYQZAMDNwRERw8AaAgKRUX+efl9+68fzUnzhFttTWmret5HwhICJY16Uh9inFEKg1I+LWKmpjpLLK9OtoJZkDuKhB9dYcVKtBc1QDa9JUKI2Hllvd63ganz6+IIdaPe8Ngbo+khsFNiRZ1p0JQsdWGxEMiTocaWGgVxdHZLeIQo7ZVN3A0YSOQ5f6sWt70Z1ctT+MgIRgjhiHLoJo1bosRCgfP374+vlLq2U8xBRDFyMxBDvWnKpdXHZhQjeDBgCqWZ0iJiPK2zoOh7pXd92WVUubb5MzDbV7eHpcbpPl1QDkdDrkvK6Xr8n0gJYCIzM68nbCEmu6tLAgREZxr4ZUNrOiksb1/UqEaLjn3NTLslTNBjJfp7vzWaDFY4hJxISGPj5+1z8ffWCVAdWtlZaXvKnc8oPiEEaykIE2L4ttOdeb1Un3un26EUVEQZG9FK2lbWVuut0ufeSYeBx6yfOKAI8vz4+jRS8GUpcbxcTpgHvOM4Gdox28OpIu2+Z5q/7a5BM/B7SAWdiChC4v++nh/uHxrm5bLXsUrBWnHOR2vZ3PJ3B0NEAFQDw9IQUCIOojYV3MAQmQG0cX78ZZr9BdwkjCAnXzyXzD8dg/vDylLgShsiylQVWjWgQQOMWsbclQYx9iwBjdqe6tqO9V3y/T4dSnY3p9mzF0cJrRr4yE4CH0Hkz5s4Vywj91MToicSCmvTYFIm3y/HzfatswYGF2x82IW62e970prkvdss5f3sd1XLJLv3bwDROwi2NptiIJBobja2sDy9mN1VtMaSrrv3/6OaYoTx+fL7/9pg0W6rd5f//6e0Q53p0EDUTCOB5A1r3kYkCikIkqckMgAAJvYEQ4gBSFTzs8RXtUAIVAMqTT/e31VdqyH4+HLZf3y7d1ye6S7u/CkExzP/TpdAqXKax530tzQKrMDZGQkIEB3BEBsqBAsG3/1HLwRuu0IPLL0zmhCxJbra6G4GaKIXAgdwVH4gjmGEXXfV33cejvnh93eTUh8Pn/dUPISB3SoLbXt89468wB2IlpOHbiyOqoaiESBS7Nb9cZTdFt3ffUDxC6mq1VjYnuTvdz+8PUfuIwAqh7QwwEANiIvMXs45XWp4gdBf4fQPZ1bbmCkXAkKohYpn3ft9RLVavFOba859h1w2HsUgR7md9/MlxREhADIoE7sUNDUBqadS7KAP97l0reFgd089KcSboAIvjHHx5SxOtlz172teSpnJ6emXh9u4UeI36Y9R/CTEiCAEAEEbwhBhfHBD4DgQMjOEgxA3VkVK3gOlD54UW+e+6tbkukHeMvX7d5gZiCSMjrZNWwnJ0egFfGAEBIREBmiBiZTbEqqDcFB2cSVXdvbCiM6u3h6E+ngU1b3tERzfvY3x1Vl+uC5fHpxATvU5kv5+EF5T4bsYMQMKADIgBuW8YtdDEgEjmI1jKMiYmRKAqMh9qlZIhrnrRCk5jG4VHKXiuhumoDKbmanabP7Pre3+8cvQkgMBiCdYQDSGqlGhqRyeHu/nAYhbjMV0s9EJbW3BTjsO67CVOIncRxGMC81f33/3y9zQWQSfvbf0z3fnwqMDQS9EZBTy/P3zN1y2365V8/W1MJsTMDSl3sDyVPxbvrDqRmLtdVybWjSl3fpZ7RKR4vl2l/nQx9TMI02s0BXA6uVJRlGB76dAREv0NO/fV1km7oPe95uTESIjWIv1+29y+X8/MZwun6Op0fWk9uWYh4XWbdM7sOhz7G4Gp9jPfH43BIr7/8ymPfDw/gYqBaSt8nDouQBGhVazFUkg6ZkbteQRG6lHpVd2ddaa+Nh3lqTnw8j6eHY1MbUnfugoDXmt/fbz1JKZnJnGGbt/22DCn8F5WtWxLSiVEFAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3BarCEpe4Z4"
      },
      "source": [
        "Thats definitely a leaf! But what kind? üòÖ\n",
        "\n",
        "Since the `'labels'` feature of this dataset is a `datasets.features.ClassLabel`, we can use it to lookup the corresponding name for this example's label ID.\n",
        "\n",
        "First, lets access the feature definition for the `'labels'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhspADExfD93",
        "outputId": "4f575edc-df1e-4da6-96cb-064ba6b32d1c"
      },
      "source": [
        "labels = ds['train'].features['labels']\n",
        "labels"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassLabel(names=['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet'], id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Btc2JQNlHDr"
      },
      "source": [
        "Now, lets print out the class label for our example. We'll do that by using the [`int2str`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=classlabel#datasets.ClassLabel.int2str) function of `ClassLabel`, which, as the name implies, lets us pass the int representation of the class to look up the string label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FIq4B4PdlMIc",
        "outputId": "718f0742-d489-4f84-9e67-ec1c680c2ac7"
      },
      "source": [
        "labels.int2str(ex['labels'])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Common Chickweed'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ds['train'].features['labels'].names\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP6MOnghl5nS",
        "outputId": "8dc31304-c57e-4131-e763-39aebdd0f2aa"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Black-grass',\n",
              " 'Charlock',\n",
              " 'Cleavers',\n",
              " 'Common Chickweed',\n",
              " 'Common wheat',\n",
              " 'Fat Hen',\n",
              " 'Loose Silky-bent',\n",
              " 'Maize',\n",
              " 'Scentless Mayweed',\n",
              " 'Shepherds Purse',\n",
              " 'Small-flowered Cranesbill',\n",
              " 'Sugar beet']"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4bXMeDDlQqQ"
      },
      "source": [
        "Turns out the leaf shown above is infected with Bean Rust, a serious disease in bean plants. üò¢\n",
        "\n",
        "Let's write a function that'll display a grid of examples from each class so we can get a better idea of what we're working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389,
          "referenced_widgets": [
            "5315730f3eb349dbbd60b4642177e894",
            "5c3785c942a54eccbd92c84bf6d495e5",
            "4e5107d30cd049f493e8156dc4c064de",
            "53d562d874bf41d0be884ab502f01cab",
            "61c7ae3bc56c4824bdd2bac18007134b",
            "685fa914b5674c8aae26a2c05572fcf3",
            "4c16827c780e40179c5d5711bfbe5e48",
            "c63e48f311f24c91ab3681e78ce599c0",
            "a2048b10cfd6434e85cad094dbee06dc",
            "02e7560d68b640db9b7849de00a48f19",
            "7c1e7f3bc5804a31a3567369b23a5f5d"
          ]
        },
        "id": "FHrhvOGCmlM2",
        "outputId": "2dcc330d-f9d0-437d-b565-f94da9b9f3ea"
      },
      "source": [
        "from transformers.utils.dummy_vision_objects import ImageGPTFeatureExtractor\n",
        "import random\n",
        "from PIL import ImageDraw, ImageFont, Image\n",
        "\n",
        "def show_examples(ds, seed: int = 1234, examples_per_class: int = 3, size=(32, 32)):\n",
        "\n",
        "    w, h = size\n",
        "    labels = ds['train'].features['labels'].names\n",
        "    grid = Image.new('RGB', size=(examples_per_class * w, len(labels) * h))\n",
        "    draw = ImageDraw.Draw(grid)\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf\", 24)\n",
        "\n",
        "    for label_id, label in enumerate(labels):\n",
        "\n",
        "        # Filter the dataset by a single label, shuffle it, and grab a few samples\n",
        "        ds_slice = ds['train'].filter(lambda ex: ex['labels'] == label_id).shuffle(seed).select(range(examples_per_class))\n",
        "\n",
        "        # Plot this label's examples along a row\n",
        "        for i, example in enumerate(ds_slice):\n",
        "            image = example['image']\n",
        "            idx = examples_per_class * label_id + i\n",
        "            box = (idx % examples_per_class * w, idx // examples_per_class * h)\n",
        "            grid.paste(image.resize(size), box=box)\n",
        "            draw.text(box, label, (255, 255, 255), font=font)\n",
        "\n",
        "    return grid\n",
        "\n",
        "show_examples(ds, seed=random.randint(0, 100), examples_per_class=3)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/3800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5315730f3eb349dbbd60b4642177e894"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-e35f266b51b1>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mshow_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-e35f266b51b1>\u001b[0m in \u001b[0;36mshow_examples\u001b[0;34m(ds, seed, examples_per_class, size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Filter the dataset by a single label, shuffle it, and grab a few samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mds_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_per_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Plot this label's examples along a row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m         }\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3529\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3531\u001b[0;31m         indices = self.map(\n\u001b[0m\u001b[1;32m   3532\u001b[0m             function=partial(\n\u001b[1;32m   3533\u001b[0m                 \u001b[0mget_indices_from_mask_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m         }\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3002\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3004\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3005\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3378\u001b[0m                         )  # Something simpler?\n\u001b[1;32m   3379\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3380\u001b[0;31m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[1;32m   3381\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m                 processed_inputs = {\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mget_indices_from_mask_function\u001b[0;34m(function, batched, with_indices, input_columns, indices_mapping, *args, **fn_kwargs)\u001b[0m\n\u001b[1;32m   6059\u001b[0m             \u001b[0;31m# inputs only contains a batch of examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6060\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6061\u001b[0;31m             \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6062\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6063\u001b[0m                 \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys_to_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys_to_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLazyBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mdecode_column\u001b[0;34m(self, column, column_name)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_column\u001b[0;34m(self, column, column_name)\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \"\"\"\n\u001b[1;32m   1885\u001b[0m         return (\n\u001b[0;32m-> 1886\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \"\"\"\n\u001b[1;32m   1885\u001b[0m         return (\n\u001b[0;32m-> 1886\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;31m# we pass the token to read and decode files from private repositories in streaming mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/features/image.py\u001b[0m in \u001b[0;36mdecode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_local_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0msource_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2982\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2984\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3o4n5p9_wto"
      },
      "source": [
        "From what I'm seeing, \n",
        "- Angular Leaf Spot: Has irregular brown patches\n",
        "- Bean Rust:  Has circular brown spots surrounded with a white-ish yellow ring\n",
        "- Healthy: ...looks healthy. ü§∑‚Äç‚ôÇÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooXr_55XICXM"
      },
      "source": [
        "## Loading ViT Feature Extractor\n",
        "\n",
        "Now that we know what our images look like and have a better understanding of the problem we're trying to solve, let's see how we can prepare these images for our model. \n",
        "\n",
        "When ViT models are trained, specific transformations are applied to images being fed into them. Use the wrong transformations on your image and the model won't be able to understand what it's seeing! üñº ‚û°Ô∏è üî¢\n",
        "\n",
        "To make sure we apply the correct transformations, we will use a [`ViTFeatureExtractor`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=classlabel#datasets.ClassLabel.int2str) initialized with a configuration that was saved along with the pretrained model we plan to use. In our case, we'll be using the [google/vit-base-patch16-224-in21k](https://huggingface.co/google/vit-base-patch16-224-in21k) model, so lets load its feature extractor from the ü§ó Hub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct6zPRixIUoI",
        "outputId": "0776e67d-d371-4061-a638-9e6120257f46"
      },
      "source": [
        "from transformers import ViTFeatureExtractor\n",
        "\n",
        "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbGIOc_FIbU7"
      },
      "source": [
        "If we print a feature extractor, we can see its configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea22sEWLIg4e",
        "outputId": "b089f5cd-7f93-4a2e-a0b9-c26148cd4f52"
      },
      "source": [
        "feature_extractor"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViTFeatureExtractor {\n",
              "  \"do_normalize\": true,\n",
              "  \"do_rescale\": true,\n",
              "  \"do_resize\": true,\n",
              "  \"image_mean\": [\n",
              "    0.5,\n",
              "    0.5,\n",
              "    0.5\n",
              "  ],\n",
              "  \"image_processor_type\": \"ViTFeatureExtractor\",\n",
              "  \"image_std\": [\n",
              "    0.5,\n",
              "    0.5,\n",
              "    0.5\n",
              "  ],\n",
              "  \"resample\": 2,\n",
              "  \"rescale_factor\": 0.00392156862745098,\n",
              "  \"size\": {\n",
              "    \"height\": 224,\n",
              "    \"width\": 224\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmhC6aSKIics"
      },
      "source": [
        "To process an image, simply pass it to the feature extractor's call function. This will return a dict containing `pixel values`, which is the numeric representation of your image that we'll pass to the model.\n",
        "\n",
        "We get a numpy array by default, but if we add the `return_tensors='pt'` argument, we'll get back `torch` tensors instead.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lne4VrXJRIe",
        "outputId": "556399d0-140a-417a-f6d6-aca8f0c28b3a"
      },
      "source": [
        "feature_extractor(image, return_tensors='pt')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': tensor([[[[-0.4902, -0.4902, -0.4902,  ..., -0.3333, -0.3333, -0.3333],\n",
              "          [-0.4902, -0.4902, -0.4902,  ..., -0.3333, -0.3333, -0.3333],\n",
              "          [-0.4902, -0.4902, -0.4902,  ..., -0.3333, -0.3333, -0.3333],\n",
              "          ...,\n",
              "          [-0.1529, -0.1529, -0.1529,  ..., -0.5137, -0.5137, -0.5137],\n",
              "          [-0.1529, -0.1529, -0.1529,  ..., -0.5137, -0.5137, -0.5137],\n",
              "          [-0.1529, -0.1529, -0.1529,  ..., -0.5137, -0.5137, -0.5137]],\n",
              "\n",
              "         [[-0.6549, -0.6549, -0.6549,  ..., -0.4353, -0.4353, -0.4353],\n",
              "          [-0.6549, -0.6549, -0.6549,  ..., -0.4353, -0.4353, -0.4353],\n",
              "          [-0.6549, -0.6549, -0.6549,  ..., -0.4353, -0.4353, -0.4353],\n",
              "          ...,\n",
              "          [-0.2078, -0.2078, -0.2078,  ..., -0.6235, -0.6235, -0.6235],\n",
              "          [-0.2078, -0.2078, -0.2078,  ..., -0.6235, -0.6235, -0.6235],\n",
              "          [-0.2078, -0.2078, -0.2078,  ..., -0.6235, -0.6235, -0.6235]],\n",
              "\n",
              "         [[-0.6863, -0.6863, -0.6863,  ..., -0.5059, -0.5059, -0.5059],\n",
              "          [-0.6863, -0.6863, -0.6863,  ..., -0.5059, -0.5059, -0.5059],\n",
              "          [-0.6863, -0.6863, -0.6863,  ..., -0.5059, -0.5059, -0.5059],\n",
              "          ...,\n",
              "          [-0.3020, -0.3020, -0.3020,  ..., -0.6863, -0.6863, -0.6863],\n",
              "          [-0.3020, -0.3020, -0.3020,  ..., -0.6863, -0.6863, -0.6863],\n",
              "          [-0.3020, -0.3020, -0.3020,  ..., -0.6863, -0.6863, -0.6863]]]])}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujbbcaIPJiAW"
      },
      "source": [
        "## Processing the Dataset\n",
        "\n",
        "Now that we know how to read in images and transform them into inputs, let's write a function that will put those two things together to process a single example from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U48pAEuMLQh"
      },
      "source": [
        "def process_example(example):\n",
        "    inputs = feature_extractor(example['image'], return_tensors='pt')\n",
        "    inputs['labels'] = example['labels']\n",
        "    return inputs"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmIilnQ-MbhG",
        "outputId": "806505cc-0fd5-4297-f89d-36dd5044fbb3"
      },
      "source": [
        "process_example(ds['train'][0])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': tensor([[[[-0.3333, -0.3333, -0.3333,  ..., -0.1686, -0.1686, -0.1686],\n",
              "          [-0.3333, -0.3333, -0.3333,  ..., -0.1686, -0.1686, -0.1686],\n",
              "          [-0.3333, -0.3333, -0.3333,  ..., -0.1686, -0.1686, -0.1686],\n",
              "          ...,\n",
              "          [-0.4588, -0.4588, -0.4588,  ..., -0.3020, -0.3020, -0.3020],\n",
              "          [-0.4588, -0.4588, -0.4588,  ..., -0.3020, -0.3020, -0.3020],\n",
              "          [-0.4588, -0.4588, -0.4588,  ..., -0.3020, -0.3020, -0.3020]],\n",
              "\n",
              "         [[-0.4745, -0.4745, -0.4745,  ..., -0.3098, -0.3098, -0.3098],\n",
              "          [-0.4745, -0.4745, -0.4745,  ..., -0.3098, -0.3098, -0.3098],\n",
              "          [-0.4745, -0.4745, -0.4745,  ..., -0.3098, -0.3098, -0.3098],\n",
              "          ...,\n",
              "          [-0.5843, -0.5843, -0.5843,  ..., -0.4902, -0.4902, -0.4902],\n",
              "          [-0.5843, -0.5843, -0.5843,  ..., -0.4902, -0.4902, -0.4902],\n",
              "          [-0.5843, -0.5843, -0.5843,  ..., -0.4902, -0.4902, -0.4902]],\n",
              "\n",
              "         [[-0.6235, -0.6235, -0.6235,  ..., -0.4980, -0.4980, -0.4980],\n",
              "          [-0.6235, -0.6235, -0.6235,  ..., -0.4980, -0.4980, -0.4980],\n",
              "          [-0.6235, -0.6235, -0.6235,  ..., -0.4980, -0.4980, -0.4980],\n",
              "          ...,\n",
              "          [-0.6941, -0.6941, -0.6941,  ..., -0.7176, -0.7176, -0.7176],\n",
              "          [-0.6941, -0.6941, -0.6941,  ..., -0.7176, -0.7176, -0.7176],\n",
              "          [-0.6941, -0.6941, -0.6941,  ..., -0.7176, -0.7176, -0.7176]]]]), 'labels': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fusnj3EHMk5g"
      },
      "source": [
        "While we could call `ds.map` and apply this to every example at once, this can be very slow, especially if you use a larger dataset. Instead, we'll apply a ***transform*** to the dataset. Transforms are only applied to examples as you index them.\n",
        "\n",
        "First, though, we'll need to update our last function to accept a batch of data, as that's what `ds.with_transform` expects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_sF61AoM3X1"
      },
      "source": [
        "# ds = load_dataset('beans')\n",
        "\n",
        "def transform(example_batch):\n",
        "    # Take a list of PIL images and turn them to pixel values\n",
        "    inputs = feature_extractor([x for x in example_batch['image']], return_tensors='pt')\n",
        "\n",
        "    # Don't forget to include the labels!\n",
        "    inputs['labels'] = example_batch['labels']\n",
        "    return inputs\n",
        "\n",
        "prepared_ds = ds.with_transform(transform)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p31_fIQ3N5ej"
      },
      "source": [
        "We can directly apply this to our dataset using `ds.with_transform(transform)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlCsAUJxOlZy"
      },
      "source": [
        "prepared_ds = ds.with_transform(transform)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xng7C3pOq9Q"
      },
      "source": [
        "Now, whenever we get an example from the dataset, our transform will be \n",
        "applied in real time (on both samples and slices, as shown below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZEwL06H9IQr",
        "outputId": "1b12682a-abba-4627-f257-f46bcbc3be4c"
      },
      "source": [
        "prepared_ds['train'][0:2]"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': tensor([[[[-0.3333, -0.3333, -0.3333,  ..., -0.1686, -0.1686, -0.1686],\n",
              "          [-0.3333, -0.3333, -0.3333,  ..., -0.1686, -0.1686, -0.1686],\n",
              "          [-0.3333, -0.3333, -0.3333,  ..., -0.1686, -0.1686, -0.1686],\n",
              "          ...,\n",
              "          [-0.4588, -0.4588, -0.4588,  ..., -0.3020, -0.3020, -0.3020],\n",
              "          [-0.4588, -0.4588, -0.4588,  ..., -0.3020, -0.3020, -0.3020],\n",
              "          [-0.4588, -0.4588, -0.4588,  ..., -0.3020, -0.3020, -0.3020]],\n",
              "\n",
              "         [[-0.4745, -0.4745, -0.4745,  ..., -0.3098, -0.3098, -0.3098],\n",
              "          [-0.4745, -0.4745, -0.4745,  ..., -0.3098, -0.3098, -0.3098],\n",
              "          [-0.4745, -0.4745, -0.4745,  ..., -0.3098, -0.3098, -0.3098],\n",
              "          ...,\n",
              "          [-0.5843, -0.5843, -0.5843,  ..., -0.4902, -0.4902, -0.4902],\n",
              "          [-0.5843, -0.5843, -0.5843,  ..., -0.4902, -0.4902, -0.4902],\n",
              "          [-0.5843, -0.5843, -0.5843,  ..., -0.4902, -0.4902, -0.4902]],\n",
              "\n",
              "         [[-0.6235, -0.6235, -0.6235,  ..., -0.4980, -0.4980, -0.4980],\n",
              "          [-0.6235, -0.6235, -0.6235,  ..., -0.4980, -0.4980, -0.4980],\n",
              "          [-0.6235, -0.6235, -0.6235,  ..., -0.4980, -0.4980, -0.4980],\n",
              "          ...,\n",
              "          [-0.6941, -0.6941, -0.6941,  ..., -0.7176, -0.7176, -0.7176],\n",
              "          [-0.6941, -0.6941, -0.6941,  ..., -0.7176, -0.7176, -0.7176],\n",
              "          [-0.6941, -0.6941, -0.6941,  ..., -0.7176, -0.7176, -0.7176]]],\n",
              "\n",
              "\n",
              "        [[[-0.3333, -0.3333, -0.3333,  ..., -0.3020, -0.3020, -0.3020],\n",
              "          [-0.3333, -0.3333, -0.3333,  ..., -0.3020, -0.3020, -0.3020],\n",
              "          [-0.3333, -0.3333, -0.3333,  ..., -0.3020, -0.3020, -0.3020],\n",
              "          ...,\n",
              "          [-0.4275, -0.4275, -0.4275,  ..., -0.3333, -0.3333, -0.3333],\n",
              "          [-0.4275, -0.4275, -0.4275,  ..., -0.3333, -0.3333, -0.3333],\n",
              "          [-0.4275, -0.4275, -0.4275,  ..., -0.3333, -0.3333, -0.3333]],\n",
              "\n",
              "         [[-0.4196, -0.4196, -0.4196,  ..., -0.4196, -0.4196, -0.4196],\n",
              "          [-0.4196, -0.4196, -0.4196,  ..., -0.4196, -0.4196, -0.4196],\n",
              "          [-0.4196, -0.4196, -0.4196,  ..., -0.4196, -0.4196, -0.4196],\n",
              "          ...,\n",
              "          [-0.5765, -0.5765, -0.5765,  ..., -0.5686, -0.5686, -0.5686],\n",
              "          [-0.5765, -0.5765, -0.5765,  ..., -0.5686, -0.5686, -0.5686],\n",
              "          [-0.5765, -0.5765, -0.5765,  ..., -0.5686, -0.5686, -0.5686]],\n",
              "\n",
              "         [[-0.5451, -0.5451, -0.5451,  ..., -0.5294, -0.5294, -0.5294],\n",
              "          [-0.5451, -0.5451, -0.5451,  ..., -0.5294, -0.5294, -0.5294],\n",
              "          [-0.5451, -0.5451, -0.5451,  ..., -0.5294, -0.5294, -0.5294],\n",
              "          ...,\n",
              "          [-0.6863, -0.6863, -0.6863,  ..., -0.7804, -0.7804, -0.7804],\n",
              "          [-0.6863, -0.6863, -0.6863,  ..., -0.7804, -0.7804, -0.7804],\n",
              "          [-0.6863, -0.6863, -0.6863,  ..., -0.7804, -0.7804, -0.7804]]]]), 'labels': [0, 6]}"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ngOi7XiTFpB"
      },
      "source": [
        "# Training and Evaluation\n",
        "\n",
        "The data is processed and we are ready to start setting up the training pipeline. We will make use of ü§ó's Trainer, but that'll require us to do a few things first:\n",
        "\n",
        "- Define a collate function.\n",
        "\n",
        "- Define an evaluation metric. During training, the model should be evaluated on its prediction accuracy. We should define a compute_metrics function accordingly.\n",
        "\n",
        "- Load a pretrained checkpoint. We need to load a pretrained checkpoint and configure it correctly for training.\n",
        "\n",
        "- Define the training configuration.\n",
        "\n",
        "After having fine-tuned the model, we will correctly evaluate it on the evaluation data and verify that it has indeed learned to correctly classify our images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRjeQr_XXI0y"
      },
      "source": [
        "### Define our data collator\n",
        "\n",
        "Batches are coming in as lists of dicts, so we just unpack + stack those into batch tensors.\n",
        "\n",
        "We return a batch `dict` from our `collate_fn` so we can simply `**unpack` the inputs to our model later. ‚ú®"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWOAPU__XLCX"
      },
      "source": [
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([x['labels'] for x in batch])\n",
        "    }"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSzB2DEzElnx"
      },
      "source": [
        "### Define an evaluation metric\n",
        "\n",
        "Here, we load the [accuracy](https://huggingface.co/metrics/accuracy) metric from `datasets`, and then write a function that takes in a model prediction + computes the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mT-g1j2U5xd"
      },
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "def compute_metrics(p):\n",
        "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GBNg3LZVDTE"
      },
      "source": [
        "Now we can load our pretrained model. We'll add `num_labels` on init to make sure the model creates a classification head with the right number of units. We'll also include the `id2label` and `label2id` mappings so we have human readable labels in the ü§ó hub widget if we choose to `push_to_hub`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ikGEXYVDPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f5ef1a-b903-4356-c807-aaaa9691e62e"
      },
      "source": [
        "from transformers import ViTForImageClassification\n",
        "\n",
        "label = ds['train'].features['labels'].names\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    num_labels=len(label),\n",
        "    id2label={str(i): c for i, c in enumerate(label)},\n",
        "    label2id={c: str(i) for i, c in enumerate(label)}\n",
        ")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
            "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeWeU33lVDNR"
      },
      "source": [
        "We're almost ready to train! The last thing we'll do before that is set up the training configuration by defining [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/trainer#transformers.TrainingArguments).\n",
        "\n",
        "Most of these are pretty self-explanatory, but one that is quite important here is `remove_unused_columns=False`. This one will drop any features not used by the model's call function. By default it's `True` because usually its ideal to drop unused feature columns, as it makes it easier to unpack inputs into the model's call function. But, in our case, we need the unused features ('image' in particular) in order to create 'pixel_values'.\n",
        "\n",
        "What I'm trying to say is that you'll have a bad time if you forget to set `remove_unused_columns=False`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6g_73VHVDKK"
      },
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=\"/content/drive/MyDrive/Colab Notebooks/CS529/plants_out\",\n",
        "  per_device_train_batch_size=16,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=1,\n",
        "  fp16=True,\n",
        "  save_steps=100,\n",
        "  eval_steps=100,\n",
        "  logging_steps=10,\n",
        "  learning_rate=2e-2,\n",
        "  save_total_limit=2,\n",
        "  remove_unused_columns=False,\n",
        "  push_to_hub=False,\n",
        "  report_to='tensorboard',\n",
        "  load_best_model_at_end=True,\n",
        ")"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMJE-CkSWTMG"
      },
      "source": [
        "Now, all instances can be passed to Trainer and we are ready to start training!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwaYQIFMVDHW"
      },
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=prepared_ds[\"train\"],\n",
        "    eval_dataset=prepared_ds[\"validation\"],\n",
        "    tokenizer=feature_extractor,\n",
        ")"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rHP8IEEVDBE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "7b729429-6f32-4e27-c378-400b87daf355"
      },
      "source": [
        "train_results = trainer.train()\n",
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 13/238 01:42 < 34:58, 0.11 it/s, Epoch 0.05/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fFsGHbLhxYK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bd92f27f-84db-4a52-95fd-fffba32e7497"
      },
      "source": [
        "metrics = trainer.evaluate(prepared_ds['validation'])\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 133\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17/17 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        4.0\n",
            "  eval_accuracy           =      0.985\n",
            "  eval_loss               =     0.0637\n",
            "  eval_runtime            = 0:00:02.13\n",
            "  eval_samples_per_second =     62.356\n",
            "  eval_steps_per_second   =       7.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dePRjHqsZM6M"
      },
      "source": [
        "kwargs = {\n",
        "    \"finetuned_from\": model.config._name_or_path,\n",
        "    \"tasks\": \"image-classification\",\n",
        "    \"dataset\": 'plants',\n",
        "    \"tags\": ['image-classification'],\n",
        "}\n",
        "\n",
        "if training_args.push_to_hub:\n",
        "    trainer.push_to_hub('üçª cheers', **kwargs)\n",
        "else:\n",
        "    trainer.create_model_card(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDv0xMywYv1-"
      },
      "source": [
        "The resulting model has been shared to [nateraw/vit-base-beans](https://huggingface.co/nateraw/vit-base-beans). I'm assuming you don't have pictures of bean leaves laying around, but if you do, you can try out the model in the browser üöÄ."
      ]
    }
  ]
}